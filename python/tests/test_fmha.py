import torch                                                                                                                                                                                                                                                                                      
import cobraml                                                                                                                                                                                                                                                                                    
                                                                                                                                                                                                                                                                                                
def vanilla_mha(q, k, v, causal=True):                                                                                                                                                                                                                                                            
    """Naive MHA: Q @ K.T @ V with no optimizations"""                                                                                                                                                                                                                                            
    B, N, H, d = q.shape                                                                                                                                                                                                                                                                          
    scale = d ** -0.5                                                                                                                                                                                                                                                                             
                                                                                                                                                                                                                                                                                                
    # [B, N, H, d] -> [B, H, N, d]                                                                                                                                                                                                                                                                
    q = q.transpose(1, 2)                                                                                                                                                                                                                                                                         
    k = k.transpose(1, 2)                                                                                                                                                                                                                                                                         
    v = v.transpose(1, 2)                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                                                                                                
    # Attention scores [B, H, N, N]                                                                                                                                                                                                                                                               
    attn = torch.matmul(q, k.transpose(-2, -1)) * scale                                                                                                                                                                                                                                           
                                                                                                                                                                                                                                                                                                
    if causal:                                                                                                                                                                                                                                                                                    
        mask = torch.triu(torch.ones(N, N, device=q.device, dtype=torch.bool), diagonal=1)                                                                                                                                                                                                        
        attn = attn.masked_fill(mask, float('-inf'))                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                
    attn = torch.softmax(attn, dim=-1)                                                                                                                                                                                                                                                            
                                                                                                                                                                                                                                                                                                
    out = torch.matmul(attn, v)                                                                                                                                                                                                                                                                   
    return out.transpose(1, 2)  # back to [B, N, H, d]                                                                                                                                                                                                                                            
                                                                                                                                                                                                                                                                                                
# Benchmark                                                                                                                                                                                                                                                                                       
B, N, H, d = 4, 512, 32, 64                                                                                                                                                                                                                                                                       
q = torch.randn(B, N, H, d, device='cuda', dtype=torch.float32)                                                                                                                                                                                                                                   
k = torch.randn(B, N, H, d, device='cuda', dtype=torch.float32)                                                                                                                                                                                                                                   
v = torch.randn(B, N, H, d, device='cuda', dtype=torch.float32)                                                                                                                                                                                                                                   
                                                                                                                                                                                                                                                                                                
# Warmup                                                                                                                                                                                                                                                                                          
for _ in range(10):                                                                                                                                                                                                                                                                               
    _ = cobraml.fmha(q, k, v, causal=False)                                                                                                                                                                                                                                                        
    _ = vanilla_mha(q, k, v, causal=False)                                                                                                                                                                                                                                                         
torch.cuda.synchronize()                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                
start = torch.cuda.Event(enable_timing=True)                                                                                                                                                                                                                                                      
end = torch.cuda.Event(enable_timing=True)                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                
# CobraML                                                                                                                                                                                                                                                                                         
start.record()                                                                                                                                                                                                                                                                                    
for _ in range(100):                                                                                                                                                                                                                                                                              
    _ = cobraml.fmha(q, k, v, causal=False)                                                                                                                                                                                                                                                        
end.record()                                                                                                                                                                                                                                                                                      
torch.cuda.synchronize()                                                                                                                                                                                                                                                                          
cobra_ms = start.elapsed_time(end) / 100                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                
# Vanilla                                                                                                                                                                                                                                                                                         
start.record()                                                                                                                                                                                                                                                                                    
for _ in range(100):                                                                                                                                                                                                                                                                              
    _ = vanilla_mha(q, k, v, causal=False)                                                                                                                                                                                                                                                         
end.record()                                                                                                                                                                                                                                                                                      
torch.cuda.synchronize()                                                                                                                                                                                                                                                                          
vanilla_ms = start.elapsed_time(end) / 100                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                
print(f"CobraML:  {cobra_ms:.3f} ms")                                                                                                                                                                                                                                                             
print(f"Vanilla:  {vanilla_ms:.3f} ms")                                                                                                                                                                                                                                                           
print(f"Speedup:  {vanilla_ms/cobra_ms:.2f}x")

# Correctness check
out_cobra = cobraml.fmha(q, k, v, causal=False)
out_vanilla = vanilla_mha(q, k, v, causal=False)

print(f"\nMax diff: {(out_cobra - out_vanilla).abs().max().item():.6f}")
print(f"Close?    {torch.allclose(out_cobra, out_vanilla, atol=1e-3, rtol=1e-3)}")

print(f"q device: {q.device}")                                                                                                                                                                                                                                                                    
print(f"out_cobra device: {out_cobra.device}")                                                                                                                                                                                                                                                    
print(f"out_vanilla device: {out_vanilla.device}")                                                                                                                                                                                                                                                
                                                    